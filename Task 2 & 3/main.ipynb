{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "CQBx-GmKCu2i",
    "outputId": "272bbb7d-b504-4a20-8a1c-0c582c64e7df"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from docx import Document\n",
    "\n",
    "# List of video names we’ll be processing\n",
    "video_names = ['B', 'C', 'D', 'E', 'F']\n",
    "\n",
    "# Lists to store the retention and script data for each video\n",
    "retention_data_list = []\n",
    "script_data_list = []\n",
    "\n",
    "# Function to extract the text from a .docx file\n",
    "def extract_text_from_docx(docx_filename):\n",
    "    doc = Document(docx_filename)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "# Now let’s go through each video in the list\n",
    "for video in video_names:\n",
    "    retention_file_path = f'your_path/VIDEO {video}.xlsx'\n",
    "    script_file_path = f'your_path/VIDEO {video}.docx'\n",
    "\n",
    "    retention_data = pd.read_excel(retention_file_path).iloc[:100, :2]\n",
    "    retention_data_list.append(retention_data)\n",
    "\n",
    "    script_text = extract_text_from_docx(script_file_path)\n",
    "    script_data_list.append(script_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zvk8X-VeQXck"
   },
   "outputs": [],
   "source": [
    "# Function to split the script text into smaller parts\n",
    "def split_script_into_parts(script_text, num_parts=100):\n",
    "    part_length = len(script_text) // num_parts\n",
    "    script_parts = []\n",
    "    \n",
    "    # Loop through the number of parts and slice the script accordingly\n",
    "    for i in range(num_parts):\n",
    "        start_index = i * part_length\n",
    "        end_index = (i + 1) * part_length if i < num_parts - 1 else len(script_text)\n",
    "        script_parts.append(script_text[start_index:end_index])\n",
    "\n",
    "    return script_parts\n",
    "\n",
    "# Now, let’s process each script text\n",
    "split_scripts_list = []\n",
    "\n",
    "for script_text in script_data_list:\n",
    "    split_script = split_script_into_parts(script_text)\n",
    "    split_scripts_list.append(split_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4MA14s8RKhM"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "\n",
    "# Loading the pre-trained DistilBERT tokenizer/model.\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "e_model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRCKju_mRmiS"
   },
   "outputs": [],
   "source": [
    "# Function to get embeddings for a given script part\n",
    "def get_embeddings(script_part):\n",
    "    inputs = tokenizer(script_part, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = e_model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)  \n",
    "    return embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0YtnumPOi1u"
   },
   "outputs": [],
   "source": [
    "embeddings_list = []\n",
    "\n",
    "# Iterate over each script in the split_scripts_list\n",
    "for split_script in split_scripts_list:\n",
    "    video_embeddings = []\n",
    "    # Iterate over each part in the split script\n",
    "    for part in split_script:\n",
    "        embedding = get_embeddings(part)\n",
    "        video_embeddings.append(embedding)\n",
    "    embeddings_list.append(np.array(video_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DlZuwAoSS4tI",
    "outputId": "4e9d72cb-a312-4f1a-98ff-bd8f82f75af6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video B has 100 embeddings.\n",
      "Video C has 100 embeddings.\n",
      "Video D has 100 embeddings.\n",
      "Video E has 100 embeddings.\n",
      "Video F has 100 embeddings.\n"
     ]
    }
   ],
   "source": [
    "# Loop through each video's embeddings in the embeddings_list\n",
    "for i, video_embeddings in enumerate(embeddings_list):\n",
    "    print(f\"Video {video_names[i]} has {len(video_embeddings)} embeddings.\")\n",
    "    if len(video_embeddings) != 100:\n",
    "        print(f\"Error: Video {video_names[i]} does not have 100 parts!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ka9x51oSS96H"
   },
   "outputs": [],
   "source": [
    "# Function to combine embeddings with video position data\n",
    "def combine_embeddings_with_position(embeddings, retention_data):\n",
    "    combined_features = []\n",
    "\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        position = retention_data.iloc[i, 0] \n",
    "        flattened_embedding = embedding.flatten()\n",
    "\n",
    "        combined_vector = np.concatenate([flattened_embedding, [position]])\n",
    "\n",
    "        combined_features.append(combined_vector)\n",
    "\n",
    "    return np.array(combined_features)\n",
    "\n",
    "final_dataset_list = []\n",
    "\n",
    "# Iterate through each video's embeddings and combine with its retention data\n",
    "for i, video_embeddings in enumerate(embeddings_list):\n",
    "    retention_data = retention_data_list[i].iloc[:100, :2]  \n",
    "\n",
    "    combined_data = combine_embeddings_with_position(video_embeddings, retention_data)\n",
    "\n",
    "    final_dataset_list.append(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHOsAaiSTznM",
    "outputId": "77850ee1-64dc-4ead-c86e-4677f1f15798"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_all = []\n",
    "Y_all = []\n",
    "\n",
    "# Loop through each video data in the final dataset list\n",
    "for i, video_data in enumerate(final_dataset_list):\n",
    "    retention_data = retention_data_list[i].iloc[:100, 1]  \n",
    "    X_all.append(video_data)\n",
    "    Y_all.append(retention_data.values)\n",
    "\n",
    "# Concatenate the lists to create the complete feature matrix (X_all) and target vector (Y_all)\n",
    "X_all = np.concatenate(X_all, axis=0)  \n",
    "Y_all = np.concatenate(Y_all, axis=0)  \n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_all, Y_all, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Evaluation function to assess model performance\n",
    "def eval(Y_test, Y_pred):\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(Y_test, Y_pred)\n",
    "    mse = mean_squared_error(Y_test, Y_pred)\n",
    "    r2 = r2_score(Y_test, Y_pred)\n",
    "    mean_target = Y_test.mean()\n",
    "    mean_squared_target = (Y_test ** 2).mean()\n",
    "    mae_percentage = (mae / mean_target) * 100 \n",
    "    mse_percentage = (mse / mean_squared_target) * 100 \n",
    "    \n",
    "    # Print the results of model evaluation\n",
    "    print(f\"Model: {type(model).__name__}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"R-squared (R²): {r2:.4f}\")\n",
    "    print(f\"MAE as Percentage of Mean Target: {mae_percentage:.2f}%\")\n",
    "    print(f\"MSE as Percentage of Mean Target Squared: {mse_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GradientBoostingRegressor\n",
      "Mean Absolute Error (MAE): 1.7302\n",
      "Mean Squared Error (MSE): 5.4279\n",
      "R-squared (R²): 0.9578\n",
      "MAE as Percentage of Mean Target: 2.82%\n",
      "MSE as Percentage of Mean Target Squared: 0.14%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instantiate the GradientBoostingRegressor model with 100 estimators (trees)\n",
    "model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# This trains the model to learn the patterns between features and target values\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Call the eval function to evaluate the model's performance on the test set\n",
    "eval(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction for Video A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jPSEMM3lUgmj",
    "outputId": "38f7c8ea-d279-4b9e-b083-0ef616832098"
   },
   "outputs": [],
   "source": [
    "# Define the file paths\n",
    "video_a_retention_path = 'your_path/VIDEO A.xlsx'\n",
    "video_a_script_path = 'your_path/VIDEO A.docx'\n",
    "\n",
    "video_a_retention = pd.read_excel(video_a_retention_path).iloc[:100, :2]\n",
    "\n",
    "# Extract the script text from the Word document (video script)\n",
    "video_a_script_text = extract_text_from_docx(video_a_script_path)\n",
    "video_a_script_parts = split_script_into_parts(video_a_script_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dfc2WvtuXT8m",
    "outputId": "0952c46f-0086-479c-c51a-0d05db280fb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video A embeddings shape: (100, 768)\n"
     ]
    }
   ],
   "source": [
    "video_a_embeddings = []\n",
    "\n",
    "# Loop through each part of the script for 'Video A'\n",
    "for part in video_a_script_parts:\n",
    "    embedding = get_embeddings(part)\n",
    "    video_a_embeddings.append(embedding)\n",
    "\n",
    "video_a_embeddings = np.array(video_a_embeddings).squeeze()\n",
    "print(f\"Video A embeddings shape: {video_a_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9NgSl1cAZFji",
    "outputId": "af5ec047-11bd-4c69-d2fa-3cd1c6fa19d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature set shape: (100, 769)\n"
     ]
    }
   ],
   "source": [
    "# Extract the 'Video position (%)' values from the retention data and reshape it into a 2D array\n",
    "video_a_positions = video_a_retention['Video position (%)'].values.reshape(-1, 1)\n",
    "# Combine the embeddings and position data horizontally to create the feature set for prediction\n",
    "video_a_features = np.hstack((video_a_embeddings, video_a_positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sHVpXT65bBlw",
    "outputId": "9c7593dd-b63f-42ce-e764-fd175f8cb185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted retention percentages for Video A (first 10):\n",
      "[98.51392039 87.4613551  83.23214272 82.95397661 79.43626736 79.73905597\n",
      " 73.76885889 79.20397959 76.47252405 79.26680629]\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to predict retention percentages for 'Video A' based on the combined features\n",
    "video_a_predictions = model.predict(video_a_features)\n",
    "print(f\"Predicted retention percentages for Video A (first 10):\\n{video_a_predictions[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New intro with GPT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "# Function to write content to a .docx file\n",
    "def write_to_docx(file_path, content):\n",
    "    doc = Document()\n",
    "    \n",
    "    for paragraph in content:\n",
    "        doc.add_paragraph(paragraph)\n",
    "    \n",
    "    doc.save(file_path)\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"new.docx\" \n",
    "video_a_retention_path = 'your_path/VIDEO A.xlsx'\n",
    "video_a_script_path = 'your_path/new.docx'\n",
    "\n",
    "# Read the first 4 rows of retention data from the Excel file\n",
    "video_a_retention = pd.read_excel(video_a_retention_path).iloc[:4, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ititration 1\n",
      "\n",
      "Result=  Get ready to cringe, laugh, and maybe shed a tear for humanity's lack of common sense. Welcome to Part 8 of Embarrassingly Dumb Ways People Died. From epic fails to mind-boggling mishaps, you won't believe how these individuals managed to meet their unlikely fate. So, grab your popcorn and get ready for a wild ride as we dive into some of the most outrageous stories of accidental exits. Let's unravel the mystery of how the not-so-bright meet their untimely end.\n",
      "Bad Retention [97.67611867 86.71235258 85.1554384  81.68914314]\n",
      "\n",
      "\n",
      "Ititration 2\n",
      "\n",
      "Result=  Get ready to cringe, laugh, and shake your head in disbelief as we dive into the world of the most Embarrassingly Dumb Ways People Died [Part 8]. We all strive to leave behind a legacy, but some individuals choose the path of ridiculousness in their final moments. From mind-boggling mishaps to jaw-dropping blunders, get ready to be both entertained and baffled. So grab a seat and prepare to be amazed by the incredibly foolish exits that some people have taken from this world.\n",
      "Bad Retention [96.64132321 87.59478196 83.95492039 84.41335965]\n",
      "\n",
      "\n",
      "Ititration 3\n",
      "\n",
      "Result=  Get ready to cringe, laugh, and maybe even facepalm as we dive into the latest installment of \"Embarrassingly Dumb Ways People Died.\" From jaw-dropping mishaps to mind-boggling accidents, these unbelievable tales will have you on the edge of your seat. So, grab a snack, buckle up, and prepare to be amazed by the outrageous antics of some truly clueless individuals. Let's jump right in and explore the absurdity of how some people meet their untimely end.\n",
      "Bad Retention [99.61115358 87.58750708 84.43857863 82.53360963]\n",
      "\n",
      "\n",
      "Ititration 4\n",
      "\n",
      "Result=  Are you ready for a wild ride through some of the craziest and most ludicrous ways people have met their end? Get ready to laugh, cringe, and maybe even shake your head in disbelief as we recount the most Embarrassingly Dumb Ways People Died in our latest installment. Trust us, you won't want to miss out on this one!\n",
      "Bad Retention [98.0255991  86.43692901 84.19466656 84.49614255]\n",
      "\n",
      "\n",
      "Ititration 5\n",
      "\n",
      "Result=  Welcome to Part 8 of Embarrassingly Dumb Ways People Died - where the stories of accidental exits take a hilariously tragic turn. From unbelievable mishaps to jaw-dropping blunders, prepare to be amazed (and maybe a little horrified) by the bizarre demises of these not-so-bright individuals. So buckle up, because we're diving into a rollercoaster ride of unbelievable demise.\n",
      "**************Found better script with retention [101.19027679  87.49154137  83.86554913  83.96865527]**************\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Function to call the OpenAI API and generate a response for the prompt\n",
    "def llm_call(prompt):\n",
    "    openai = OpenAI(\n",
    "    api_key= 'your_key')\n",
    "\n",
    "    message = [\n",
    "        {\"role\":\"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    # Generate the response from GPT-3.5 model using the provided prompt\n",
    "    response= openai.chat.completions.create(\n",
    "        messages= message,\n",
    "        model= \"gpt-4\"\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Initial video script (intro) to be improved\n",
    "full_text = '''Embarrassingly Dumb Ways People Died [Part 8]\n",
    "We’d all like to be remembered for something great. But, surprisingly often, incredibly dumb folks leave this world with a parting tale they’d probably prefer to be forgotten. That said, some of these spectacularly dim-witted, accidental exit strategies are irresistibly entertaining to hear about. So, without further ado, let’s check out some of the most Embarrassingly Dumb Ways People Died.\n",
    "'''\n",
    "\n",
    "# Define the prompt to instruct GPT to improve the intro\n",
    "prompt = f\"\"\"The goal is to improve this video script intro to increase audience retention. Focus on:\n",
    "- Capturing attention within the first 10 seconds.\n",
    "- Using clear, vivid, and relatable language.\n",
    "- Creating curiosity or excitement about the content.\n",
    "- Ensuring the tone matches the audience (e.g., humorous, dramatic, or suspenseful).\n",
    "\n",
    "Here is the current intro:\n",
    "{full_text}\n",
    "\n",
    "Rewrite the intro to maximize engagement and retention.\n",
    "\"\"\"\n",
    "\n",
    "# Initial old retention data to compare new retention against\n",
    "r_into= np.array([98.51392039, 87.4613551,  83.23214272, 82.95397661])\n",
    "\n",
    "# Loop through 60 iterations to improve the script and evaluate retention\n",
    "for i in range(60):\n",
    "    print(f\"Ititration {i+1}\\n\")\n",
    "    split_scripts_list = []\n",
    "    video_a_embeddings = []\n",
    "    # Call the OpenAI model to rewrite the script intro\n",
    "    result= llm_call(prompt)\n",
    "    print(\"Result= \", result)\n",
    "    with open('content.txt', 'a', encoding=\"utf-8\") as file:\n",
    "        file.write(result)\n",
    "    write_to_docx(file_path, [result])\n",
    "    video_a_script_text = extract_text_from_docx(video_a_script_path)\n",
    "    video_a_script_parts = split_script_into_parts(video_a_script_text, 4)   \n",
    "    # Generate embeddings for each script part \n",
    "    for part in video_a_script_parts:\n",
    "        embedding = get_embeddings(part)\n",
    "        video_a_embeddings.append(embedding)\n",
    "    video_a_embeddings = np.array(video_a_embeddings).squeeze()\n",
    "    video_a_positions = video_a_retention['Video position (%)'].values.reshape(-1, 1)\n",
    "    video_a_features = np.hstack((video_a_embeddings, video_a_positions))\n",
    "    new= model.predict(video_a_features)\n",
    "    # Compare the new retention with the old to check if the new script is an improvement\n",
    "    if (r_into<new).all():\n",
    "        print(f\"**************Found better script with retention {new}**************\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Bad Retention {new}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New prediction for Video A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted retention percentages for Video new intro (first 10):\n",
      "[101.76653421  89.45836529  84.08765851  83.94456804  80.08805334\n",
      "  78.63243904  79.61561589]\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "video_a_retention_path = 'your_path/VIDEO A.xlsx'\n",
    "video_a_script_path = 'your_path/with new intro.docx'\n",
    "\n",
    "video_a_retention = pd.read_excel(video_a_retention_path).iloc[:100, :2]\n",
    "video_a_script_text = extract_text_from_docx(video_a_script_path)\n",
    "video_a_script_parts = split_script_into_parts(video_a_script_text)\n",
    "video_a_embeddings = []\n",
    "\n",
    "# Loop through each script part to generate embeddings\n",
    "for part in video_a_script_parts:\n",
    "    embedding = get_embeddings(part)\n",
    "    video_a_embeddings.append(embedding)\n",
    "video_a_embeddings = np.array(video_a_embeddings).squeeze()\n",
    "video_a_positions = video_a_retention['Video position (%)'].values.reshape(-1, 1)\n",
    "video_a_features = np.hstack((video_a_embeddings, video_a_positions))\n",
    "\n",
    "# Use the trained machine learning model to predict retention percentages based on the features\n",
    "video_a_predictions = model.predict(video_a_features)\n",
    "print(f\"Predicted retention percentages for Video new intro (first 10):\\n{video_a_predictions[:7]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "envbam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
