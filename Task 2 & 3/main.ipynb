{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "CQBx-GmKCu2i",
    "outputId": "272bbb7d-b504-4a20-8a1c-0c582c64e7df"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from docx import Document\n",
    "\n",
    "video_names = ['B', 'C', 'D', 'E', 'F']\n",
    "\n",
    "retention_data_list = []\n",
    "script_data_list = []\n",
    "\n",
    "def extract_text_from_docx(docx_filename):\n",
    "    doc = Document(docx_filename)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "for video in video_names:\n",
    "    retention_file_path = f'C:/Users/bibas/Downloads/GenAI/pytorch/bam/t_2/VIDEO {video}.xlsx'\n",
    "    script_file_path = f'C:/Users/bibas/Downloads/GenAI/pytorch/bam/t_2/VIDEO {video}.docx'\n",
    "\n",
    "    retention_data = pd.read_excel(retention_file_path).iloc[:100, :2]\n",
    "    retention_data_list.append(retention_data)\n",
    "\n",
    "    script_text = extract_text_from_docx(script_file_path)\n",
    "    script_data_list.append(script_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWXBrw92H8Kv",
    "outputId": "0b04adde-6d8a-44e1-a31c-18bb277b3efd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retention Data for VIDEO B:\n",
      "  Video position (%) Absolute audience retention (%)\n",
      "0                  0                          103.63\n",
      "1                  1                           87.91\n",
      "2                  2                           84.54\n",
      "3                  3                           81.15\n",
      "4                  4                           81.26\n",
      "5                  5                              80\n",
      "6                  6                           80.35\n",
      "7                  7                           79.02\n",
      "8                  8                           79.04\n",
      "9                  9                           78.65\n"
     ]
    }
   ],
   "source": [
    "print(\"Retention Data for VIDEO B:\")\n",
    "print(retention_data_list[0].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nzXS7qviBItI",
    "outputId": "9d1ce086-c3d2-4bc2-9c7b-c47293663f0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Video position (%) Absolute audience retention (%)\n",
      "0                   0                          103.97\n",
      "1                   1                           89.17\n",
      "2                   2                           85.68\n",
      "3                   3                           84.62\n",
      "4                   4                           83.14\n",
      "..                ...                             ...\n",
      "95                 95                           52.08\n",
      "96                 96                            51.9\n",
      "97                 97                           51.53\n",
      "98                 98                           44.35\n",
      "99                 99                           29.98\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "Embarrassingly Dumb Ways People Died - Darwin Awards Winners Part 2\n",
      "Natural selection is mother nature’s way of making sure people get smarter - but even after 200,000 years of human evolution, some of us are still making really terrible choices. Let’s take a look at some of the most foolish examples now.\n",
      "20. Way Too Hot Spring\n",
      "Have you ever fancied a dip in a hot spring? I know I have – especially when clothing is optional. Maybe this was what Colin Scott was thinking when he strayed off the tr\n"
     ]
    }
   ],
   "source": [
    "print(retention_data_list[1]) \n",
    "print(script_data_list[1][:500])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Zvk8X-VeQXck"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_script_into_parts(script_text, num_parts=100):\n",
    "    part_length = len(script_text) // num_parts\n",
    "    script_parts = []\n",
    "\n",
    "    for i in range(num_parts):\n",
    "        start_index = i * part_length\n",
    "        end_index = (i + 1) * part_length if i < num_parts - 1 else len(script_text)\n",
    "        script_parts.append(script_text[start_index:end_index])\n",
    "\n",
    "    return script_parts\n",
    "\n",
    "split_scripts_list = []\n",
    "\n",
    "for script_text in script_data_list:\n",
    "    split_script = split_script_into_parts(script_text)\n",
    "    split_scripts_list.append(split_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_nc-kELQqBc",
    "outputId": "d3a63abb-9489-4ab2-adf1-7aef7e5bc547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video B - First 5 parts of the script:\n",
      "Part 1: When Charles Darwin developed his Theory of Evolution he discovered animals bred selectively, so the...\n",
      "Part 2: the species were more likely to mate and pass on their DNA. Darwin called this Natural Selection. Bu...\n",
      "Part 3: f so stupid they actually die, and so no longer have the ability to pass their DNA to future generat...\n",
      "Part 4:  the Darwin Awards were created as a tongue in cheek way to remember those people who have removed t...\n",
      "Part 5: rough their own stupidity. Coming up, are the top 20 dumbest of the dumb Darwin Award winners.\n",
      "\n",
      "20. ...\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Video C - First 5 parts of the script:\n",
      "Part 1: Embarrassingly Dumb Ways People Died - Darwin Awards Winners Part 2\n",
      "Natural selection is mother natu...\n",
      "Part 2: - but even after 200,000 years of human evolution, some of us are still making really terrible choic...\n",
      "Part 3: oolish examples now.\n",
      "20. Way Too Hot Spring\n",
      "Have you ever fancied a dip in a hot spring? I know I ha...\n",
      "Part 4: Maybe this was what Colin Scott was thinking when he strayed off the trail at Yellowstone in 2016 to...\n",
      "Part 5: gs. This activity is forbidden by park rules, but Colin - a former nature reserve volunteer, thought...\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Video D - First 5 parts of the script:\n",
      "Part 1: Embarrassingly Dumb Ways People Died - Darwin Awards Winners [Part 4]\n",
      "The advancement of civilisatio...\n",
      "Part 2: e to those whose lack of awareness might’ve got them killed in the past. But there are some people t...\n",
      "Part 3: ions, even the achievements of the modern world can’t keep them alive. Let’s dive into some unbeliev...\n",
      "Part 4: earning themselves a Darwin award for natural selection. \n",
      "“Garbage Day!”\n",
      "No one likes having to take...\n",
      "Part 5: n… [run clip] …but we don’t usually expect to find ourselves carried off alongside our garbage. But ...\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Video E - First 5 parts of the script:\n",
      "Part 1: Embarrassingly Dumb Ways People Died - Darwin Awards Winners [Part 5]\n",
      "Sometimes, it really does seem...\n",
      "Part 2: ld is getting dumber. That may be partly due to the fact that our incredible social systems of medic...\n",
      "Part 3: y and welfare have effectively wiped out natural selection for us humans. But every once in a while,...\n",
      "Part 4: hy of a Darwin Award removes themselves from the gene pool like a deer with a penchant for highway j...\n",
      "Part 5: me now, as I take a look at some of the most mind-bogglingly dumb ways people have died.\n",
      "Leap of Fai...\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Video F - First 5 parts of the script:\n",
      "Part 1: Embarrassingly Dumb Ways People Died - Darwin Awards Winners [Part 6]\n",
      "For most of us, the natural in...\n",
      "Part 2: tty effective at keeping us from serious harm. But for some people, the impulse to carry out acts of...\n",
      "Part 3: pidity somehow overwhelms the rational mind’s urge to survive. Without further ado, get ready to be ...\n",
      "Part 4: who became real-life examples of natural selection in action. \n",
      "Quick Eggs-It\n",
      "As far as humanity’s gr...\n",
      "Part 5:  concerned, it’s fair to assume none of them have been regular participants in eating contests. But ...\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, split_script in enumerate(split_scripts_list):\n",
    "    print(f\"Video {video_names[i]} - First 5 parts of the script:\")\n",
    "    for j in range(min(5, len(split_script))):  # Show the first 5 parts for each video\n",
    "        print(f\"Part {j+1}: {split_script[j][:100]}...\")  # Display first 100 characters of each part\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "x4MA14s8RKhM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bibas\\anaconda3\\envs\\envbam\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "e_model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DRCKju_mRmiS"
   },
   "outputs": [],
   "source": [
    "def get_embeddings(script_part):\n",
    "    inputs = tokenizer(script_part, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = e_model(**inputs)\n",
    "\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)  \n",
    "    return embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "w0YtnumPOi1u"
   },
   "outputs": [],
   "source": [
    "embeddings_list = []\n",
    "\n",
    "for split_script in split_scripts_list:\n",
    "    video_embeddings = []\n",
    "\n",
    "    for part in split_script:\n",
    "        embedding = get_embeddings(part)\n",
    "        video_embeddings.append(embedding)\n",
    "\n",
    "    embeddings_list.append(np.array(video_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GZBdtVPlNAeD",
    "outputId": "e85e8f57-f900-4c10-d5e7-5c35a7adbd02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the shape of the first embedding for the first part of the first video:\n",
      "Embedding shape for the first part: (1, 768)\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking the shape of the first embedding for the first part of the first video:\")\n",
    "first_video_embeddings = embeddings_list[0]\n",
    "print(f\"Embedding shape for the first part: {first_video_embeddings[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DlZuwAoSS4tI",
    "outputId": "4e9d72cb-a312-4f1a-98ff-bd8f82f75af6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video B has 100 embeddings.\n",
      "Video C has 100 embeddings.\n",
      "Video D has 100 embeddings.\n",
      "Video E has 100 embeddings.\n",
      "Video F has 100 embeddings.\n"
     ]
    }
   ],
   "source": [
    "for i, video_embeddings in enumerate(embeddings_list):\n",
    "    print(f\"Video {video_names[i]} has {len(video_embeddings)} embeddings.\")\n",
    "    if len(video_embeddings) != 100:\n",
    "        print(f\"Error: Video {video_names[i]} does not have 100 parts!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ka9x51oSS96H"
   },
   "outputs": [],
   "source": [
    "def combine_embeddings_with_position(embeddings, retention_data):\n",
    "    combined_features = []\n",
    "\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        position = retention_data.iloc[i, 0] \n",
    "        flattened_embedding = embedding.flatten()\n",
    "\n",
    "        combined_vector = np.concatenate([flattened_embedding, [position]])\n",
    "\n",
    "        combined_features.append(combined_vector)\n",
    "\n",
    "    return np.array(combined_features)\n",
    "\n",
    "final_dataset_list = []\n",
    "\n",
    "for i, video_embeddings in enumerate(embeddings_list):\n",
    "    retention_data = retention_data_list[i].iloc[:100, :2]  \n",
    "\n",
    "    combined_data = combine_embeddings_with_position(video_embeddings, retention_data)\n",
    "\n",
    "    final_dataset_list.append(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bQlafVRmToCn",
    "outputId": "7869d6c5-dc27-45c8-bdf6-7dfca1dc76c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos in final dataset: 5\n",
      "Shape of combined data for first video: (100, 769)\n",
      "Shape of combined data for last video: (100, 769)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of videos in final dataset: {len(final_dataset_list)}\")\n",
    "\n",
    "print(f\"Shape of combined data for first video: {final_dataset_list[0].shape}\")\n",
    "\n",
    "print(f\"Shape of combined data for last video: {final_dataset_list[-1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHOsAaiSTznM",
    "outputId": "77850ee1-64dc-4ead-c86e-4677f1f15798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (400, 769)\n",
      "X_test shape: (100, 769)\n",
      "Y_train shape: (400,)\n",
      "Y_test shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_all = []\n",
    "Y_all = []\n",
    "\n",
    "for i, video_data in enumerate(final_dataset_list):\n",
    "    retention_data = retention_data_list[i].iloc[:100, 1]  \n",
    "\n",
    "    X_all.append(video_data)\n",
    "    Y_all.append(retention_data.values)\n",
    "\n",
    "X_all = np.concatenate(X_all, axis=0)  \n",
    "Y_all = np.concatenate(Y_all, axis=0)  \n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_all, Y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Y_train shape: {Y_train.shape}\")\n",
    "print(f\"Y_test shape: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def eval(Y_test, Y_pred):\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(Y_test, Y_pred)\n",
    "    mse = mean_squared_error(Y_test, Y_pred)\n",
    "    r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "    mean_target = Y_test.mean()\n",
    "    mean_squared_target = (Y_test ** 2).mean()\n",
    "\n",
    "    mae_percentage = (mae / mean_target) * 100 \n",
    "    mse_percentage = (mse / mean_squared_target) * 100 \n",
    "\n",
    "    print(f\"Model: {type(model).__name__}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"R-squared (R²): {r2:.4f}\")\n",
    "    print(f\"MAE as Percentage of Mean Target: {mae_percentage:.2f}%\")\n",
    "    print(f\"MSE as Percentage of Mean Target Squared: {mse_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GradientBoostingRegressor\n",
      "Mean Absolute Error (MAE): 1.7302\n",
      "Mean Squared Error (MSE): 5.4279\n",
      "R-squared (R²): 0.9578\n",
      "MAE as Percentage of Mean Target: 2.82%\n",
      "MSE as Percentage of Mean Target Squared: 0.14%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "eval(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction for Video A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jPSEMM3lUgmj",
    "outputId": "38f7c8ea-d279-4b9e-b083-0ef616832098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retention data (first 7 rows):\n",
      "  Video position (%) Absolute audience retention (%)\n",
      "0                  0                             NaN\n",
      "1                  1                             NaN\n",
      "2                  2                             NaN\n",
      "3                  3                             NaN\n",
      "4                  4                             NaN\n",
      "5                  5                             NaN\n",
      "6                  6                           80.63\n",
      "Script part 0:\n",
      "Embarrassingly Dumb Ways People Died [Part 8]\n",
      "We’d all like to be remembered for something great. But, surprisingly often, inc\n",
      "Script part 1:\n",
      "redibly dumb folks leave this world with a parting tale they’d probably prefer to be forgotten. That said, some of these spect\n",
      "Script part 2:\n",
      "acularly dim-witted, accidental exit strategies are irresistibly entertaining to hear about. So, without further ado, let’s ch\n",
      "Script part 3:\n",
      "eck out some of the most Embarrassingly Dumb Ways People Died.\n",
      "Labels? What Labels? \n",
      "Whenever blowtorches fall into the hands \n",
      "Script part 4:\n",
      "of the less-than-brightest members of our species, it’s always best to take a few steps back. By which I mean, move to the nex\n",
      "Script part 5:\n",
      "t county over. If this piece of common sense wasn’t already obvious, a man from Topeka, Kansas certainly made it clear in June\n"
     ]
    }
   ],
   "source": [
    "video_a_retention_path = 'C:/Users/bibas/Downloads/GenAI/pytorch/bam/t_2/VIDEO A.xlsx'\n",
    "video_a_script_path = 'C:/Users/bibas/Downloads/GenAI/pytorch/bam/t_2/VIDEO A.docx'\n",
    "\n",
    "video_a_retention = pd.read_excel(video_a_retention_path).iloc[:100, :2]\n",
    "\n",
    "video_a_script_text = extract_text_from_docx(video_a_script_path)\n",
    "\n",
    "video_a_script_parts = split_script_into_parts(video_a_script_text)\n",
    "\n",
    "print(f\"Retention data (first 7 rows):\\n{video_a_retention.head(7)}\")\n",
    "for i in range(6):\n",
    "    print(f\"Script part {i}:\\n{video_a_script_parts[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dfc2WvtuXT8m",
    "outputId": "0952c46f-0086-479c-c51a-0d05db280fb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video A embeddings shape: (100, 768)\n"
     ]
    }
   ],
   "source": [
    "video_a_embeddings = []\n",
    "\n",
    "for part in video_a_script_parts:\n",
    "    embedding = get_embeddings(part)\n",
    "    video_a_embeddings.append(embedding)\n",
    "\n",
    "video_a_embeddings = np.array(video_a_embeddings).squeeze()\n",
    "\n",
    "print(f\"Video A embeddings shape: {video_a_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9NgSl1cAZFji",
    "outputId": "af5ec047-11bd-4c69-d2fa-3cd1c6fa19d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature set shape: (100, 769)\n"
     ]
    }
   ],
   "source": [
    "video_a_positions = video_a_retention['Video position (%)'].values.reshape(-1, 1)\n",
    "\n",
    "video_a_features = np.hstack((video_a_embeddings, video_a_positions))\n",
    "\n",
    "print(f\"Final feature set shape: {video_a_features.shape}\")\n",
    "# print(f\"First feature vector:\\n{video_a_features[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sHVpXT65bBlw",
    "outputId": "9c7593dd-b63f-42ce-e764-fd175f8cb185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted retention percentages for Video A (first 10):\n",
      "[98.51392039 87.4613551  83.23214272 82.95397661 79.43626736 79.73905597\n",
      " 73.76885889 79.20397959 76.47252405 79.26680629]\n"
     ]
    }
   ],
   "source": [
    "video_a_predictions = model.predict(video_a_features)\n",
    "\n",
    "print(f\"Predicted retention percentages for Video A (first 10):\\n{video_a_predictions[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New intro with GPT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "def write_to_docx(file_path, content):\n",
    "    doc = Document()\n",
    "    \n",
    "    for paragraph in content:\n",
    "        doc.add_paragraph(paragraph)\n",
    "    \n",
    "    doc.save(file_path)\n",
    "\n",
    "file_path = \"new.docx\" \n",
    "\n",
    "video_a_retention_path = 'C:/Users/bibas/Downloads/GenAI/pytorch/bam/t_2/VIDEO A.xlsx'\n",
    "video_a_script_path = 'C:/Users/bibas/Downloads/GenAI/pytorch/bam/t_2/new.docx'\n",
    "\n",
    "video_a_retention = pd.read_excel(video_a_retention_path).iloc[:4, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ititration 1\n",
      "\n",
      "Result=  Get ready to cringe, laugh, and maybe shed a tear for humanity's lack of common sense. Welcome to Part 8 of Embarrassingly Dumb Ways People Died. From epic fails to mind-boggling mishaps, you won't believe how these individuals managed to meet their unlikely fate. So, grab your popcorn and get ready for a wild ride as we dive into some of the most outrageous stories of accidental exits. Let's unravel the mystery of how the not-so-bright meet their untimely end.\n",
      "Bad Retention [97.67611867 86.71235258 85.1554384  81.68914314]\n",
      "\n",
      "\n",
      "Ititration 2\n",
      "\n",
      "Result=  Get ready to cringe, laugh, and shake your head in disbelief as we dive into the world of the most Embarrassingly Dumb Ways People Died [Part 8]. We all strive to leave behind a legacy, but some individuals choose the path of ridiculousness in their final moments. From mind-boggling mishaps to jaw-dropping blunders, get ready to be both entertained and baffled. So grab a seat and prepare to be amazed by the incredibly foolish exits that some people have taken from this world.\n",
      "Bad Retention [96.64132321 87.59478196 83.95492039 84.41335965]\n",
      "\n",
      "\n",
      "Ititration 3\n",
      "\n",
      "Result=  Get ready to cringe, laugh, and maybe even facepalm as we dive into the latest installment of \"Embarrassingly Dumb Ways People Died.\" From jaw-dropping mishaps to mind-boggling accidents, these unbelievable tales will have you on the edge of your seat. So, grab a snack, buckle up, and prepare to be amazed by the outrageous antics of some truly clueless individuals. Let's jump right in and explore the absurdity of how some people meet their untimely end.\n",
      "Bad Retention [99.61115358 87.58750708 84.43857863 82.53360963]\n",
      "\n",
      "\n",
      "Ititration 4\n",
      "\n",
      "Result=  Are you ready for a wild ride through some of the craziest and most ludicrous ways people have met their end? Get ready to laugh, cringe, and maybe even shake your head in disbelief as we recount the most Embarrassingly Dumb Ways People Died in our latest installment. Trust us, you won't want to miss out on this one!\n",
      "Bad Retention [98.0255991  86.43692901 84.19466656 84.49614255]\n",
      "\n",
      "\n",
      "Ititration 5\n",
      "\n",
      "Result=  Welcome to Part 8 of Embarrassingly Dumb Ways People Died - where the stories of accidental exits take a hilariously tragic turn. From unbelievable mishaps to jaw-dropping blunders, prepare to be amazed (and maybe a little horrified) by the bizarre demises of these not-so-bright individuals. So buckle up, because we're diving into a rollercoaster ride of unbelievable demise.\n",
      "**************Found better script with retention [101.19027679  87.49154137  83.86554913  83.96865527]**************\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def llm_call(prompt):\n",
    "    openai = OpenAI(\n",
    "    api_key= 'your_key')\n",
    "\n",
    "    message = [\n",
    "        {\"role\":\"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    response= openai.chat.completions.create(\n",
    "        messages= message,\n",
    "        model= \"gpt-3.5-turbo\"\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "full_text = '''Embarrassingly Dumb Ways People Died [Part 8]\n",
    "We’d all like to be remembered for something great. But, surprisingly often, incredibly dumb folks leave this world with a parting tale they’d probably prefer to be forgotten. That said, some of these spectacularly dim-witted, accidental exit strategies are irresistibly entertaining to hear about. So, without further ado, let’s check out some of the most Embarrassingly Dumb Ways People Died.\n",
    "'''\n",
    "\n",
    "prompt = f\"\"\"The goal is to improve this video script intro to increase audience retention. Focus on:\n",
    "- Capturing attention within the first 10 seconds.\n",
    "- Using clear, vivid, and relatable language.\n",
    "- Creating curiosity or excitement about the content.\n",
    "- Ensuring the tone matches the audience (e.g., humorous, dramatic, or suspenseful).\n",
    "\n",
    "Here is the current intro:\n",
    "{full_text}\n",
    "\n",
    "Rewrite the intro to maximize engagement and retention.\n",
    "\"\"\"\n",
    "# print(prompt)\n",
    "\n",
    "r_into= np.array([98.51392039, 87.4613551,  83.23214272, 82.95397661])\n",
    "\n",
    "for i in range(60):\n",
    "    print(f\"Ititration {i+1}\\n\")\n",
    "    split_scripts_list = []\n",
    "    video_a_embeddings = []\n",
    "\n",
    "    result= llm_call(prompt)\n",
    "    print(\"Result= \", result)\n",
    "\n",
    "    with open('content.txt', 'a', encoding=\"utf-8\") as file:\n",
    "        file.write(result)\n",
    "    \n",
    "    write_to_docx(file_path, [result])\n",
    "\n",
    "    video_a_script_text = extract_text_from_docx(video_a_script_path)\n",
    "\n",
    "    video_a_script_parts = split_script_into_parts(video_a_script_text, 4)\n",
    "\n",
    "    # Check results\n",
    "    # print(f\"Retention data (first 7 rows):\\n{video_a_retention}\")\n",
    "    # for i in range(4):\n",
    "    #     print(f\"Script part {i}:\\n{video_a_script_parts[i]}\")\n",
    "    \n",
    "    for part in video_a_script_parts:\n",
    "        embedding = get_embeddings(part)\n",
    "        video_a_embeddings.append(embedding)\n",
    "\n",
    "    video_a_embeddings = np.array(video_a_embeddings).squeeze()\n",
    "\n",
    "    # print(f\"Video A embeddings shape: {video_a_embeddings.shape}\")\n",
    "\n",
    "    video_a_positions = video_a_retention['Video position (%)'].values.reshape(-1, 1)\n",
    "\n",
    "    video_a_features = np.hstack((video_a_embeddings, video_a_positions))\n",
    "\n",
    "    # Check the shape of the final feature set\n",
    "    # print(f\"Final feature set shape: {video_a_features.shape}\")\n",
    "    # print(f\"First feature vector:\\n{video_a_features[0]}\")\n",
    "\n",
    "    new= model.predict(video_a_features)\n",
    "    \n",
    "    if (r_into<new).all():\n",
    "        print(f\"**************Found better script with retention {new}**************\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Bad Retention {new}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted retention percentages for Video new intro (first 10):\n",
      "[101.76653421  89.45836529  84.08765851  83.94456804  80.08805334\n",
      "  78.63243904  79.61561589]\n"
     ]
    }
   ],
   "source": [
    "# 98.51392039, 87.4613551,  83.23214272, 82.95397661\n",
    "video_a_retention_path = 'C:/Users/bibas/Downloads/GenAI/pytorch/bam/t_2/VIDEO A.xlsx'\n",
    "video_a_script_path = 'C:/Users/bibas/Downloads/GenAI/pytorch/bam/t_2/with new intro.docx'\n",
    "\n",
    "video_a_retention = pd.read_excel(video_a_retention_path).iloc[:100, :2]\n",
    "\n",
    "video_a_script_text = extract_text_from_docx(video_a_script_path)\n",
    "\n",
    "video_a_script_parts = split_script_into_parts(video_a_script_text)\n",
    "\n",
    "# print(f\"Retention data (first 7 rows):\\n{video_a_retention.head(7)}\")\n",
    "# for i in range(6):\n",
    "#     print(f\"Script part {i}:\\n{video_a_script_parts[i]}\")\n",
    "\n",
    "video_a_embeddings = []\n",
    "\n",
    "for part in video_a_script_parts:\n",
    "    embedding = get_embeddings(part)\n",
    "    video_a_embeddings.append(embedding)\n",
    "\n",
    "video_a_embeddings = np.array(video_a_embeddings).squeeze()\n",
    "\n",
    "# print(f\"Video A embeddings shape: {video_a_embeddings.shape}\")\n",
    "\n",
    "video_a_positions = video_a_retention['Video position (%)'].values.reshape(-1, 1)\n",
    "\n",
    "video_a_features = np.hstack((video_a_embeddings, video_a_positions))\n",
    "\n",
    "# print(f\"Final feature set shape: {video_a_features.shape}\")\n",
    "# print(f\"First feature vector:\\n{video_a_features[0]}\")\n",
    "\n",
    "video_a_predictions = model.predict(video_a_features)\n",
    "\n",
    "print(f\"Predicted retention percentages for Video new intro (first 10):\\n{video_a_predictions[:7]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "envbam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
